# Big O Notation

Big O notation is a way to analyze performance of an algorithm.
Big O shows how an algorithm's worst-case performance will scale with input size n.
For example, an algorithm with a constant time regardless of input will be O(1).
However, an algorithm that scales linearly will have O(n) time.
In BigO.cs, I wrote three methods with three different Big O ratings.